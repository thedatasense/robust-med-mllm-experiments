{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/thedatasense/llm-healthcare/blob/main/MIMIC_GPT_Evaluation_C.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "d4b6ArvcGvFf",
    "ExecuteTime": {
     "end_time": "2025-03-03T04:59:54.259393Z",
     "start_time": "2025-03-03T04:59:53.580616Z"
    }
   },
   "source": [
    "import sys\n",
    "!pip install -q  sqlalchemy cockroachdb pandas psycopg2-binary matplotlib"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RPISEELWNK4h",
    "outputId": "4cccb605-d515-4cf0-c658-76d3e1753f8c",
    "ExecuteTime": {
     "end_time": "2025-03-03T04:59:54.735925Z",
     "start_time": "2025-03-03T04:59:54.265383Z"
    }
   },
   "source": [
    "!curl --create-dirs -o $HOME/.postgresql/root.crt 'https://cockroachlabs.cloud/clusters/5bbbe91d-b65e-410e-a783-597c93f501f6/cert'"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\r\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\r\n",
      "100  2728    0  2728    0     0   8404      0 --:--:-- --:--:-- --:--:--  8419\r\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "mYj_N4onKe2h",
    "ExecuteTime": {
     "end_time": "2025-03-03T04:59:56.512483Z",
     "start_time": "2025-03-03T04:59:54.799445Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "from IPython.display import clear_output\n",
    "from sqlalchemy.engine import create_engine\n",
    "#from datasets import load_dataset\n",
    "from openai import OpenAI\n",
    "import io\n",
    "import base64\n",
    "import random\n",
    "import requests\n",
    "import torch\n",
    "from PIL import Image\n",
    "#from transformers import AutoProcessor,Qwen2_5_VLForConditionalGeneration\n",
    "#from qwen_vl_utils import process_vision_info\n",
    "import os\n",
    "import pandas as pd\n",
    "from sqlalchemy.engine import create_engine\n",
    "#from transformers import AutoProcessor, BitsAndBytesConfig\n",
    "import json\n",
    "import yaml\n",
    "import platform\n",
    "from sqlalchemy import text\n",
    "from IPython.display import display,clear_output\n",
    "import time\n",
    "import json\n"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T04:59:56.518102Z",
     "start_time": "2025-03-03T04:59:56.515276Z"
    }
   },
   "source": [
    "cnfig_file=\"/Users/bineshkumar/Documents/config.yaml\"\n",
    "def get_from_cnfg(key_path,file_path=cnfig_file):\n",
    "    try:\n",
    "        with open(file_path, 'r') as file:\n",
    "            data = yaml.safe_load(file)\n",
    "\n",
    "        keys = key_path.split('.')\n",
    "        value = data\n",
    "        for key in keys:\n",
    "            value = value[key]\n",
    "        return value\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File {file_path} not found\")\n",
    "    except yaml.YAMLError as e:\n",
    "        print(f\"YAML parsing error: {e}\")\n",
    "    except KeyError:\n",
    "        print(f\"Key path {key_path} not found\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "    return None\n",
    "os_name = platform.system()"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T04:59:56.600390Z",
     "start_time": "2025-03-03T04:59:56.522393Z"
    }
   },
   "source": [
    "if 'google.colab' in sys.modules:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    from google.colab import userdata\n",
    "    engine = create_engine(userdata.get('DB_URL'))\n",
    "    gem_key=userdata.get('DB_URL')\n",
    "    oai_key=userdata.get('DB_URL')\n",
    "    source_folder='/content/drive/MyDrive/Health_Data/MIMIC_JPG_AVL/mimic-cxr-jpg/2.1.0/files/'\n",
    "elif os_name == \"Darwin\":\n",
    "    cnfig_file=\"/Users/bineshkumar/Documents/config.yaml\"\n",
    "    DB_URL = get_from_cnfg(\"cd_url\",cnfig_file)\n",
    "    gem_key=get_from_cnfg(\"gem_token\",cnfig_file)\n",
    "    oai_key=get_from_cnfg(\"oai_token\",cnfig_file)\n",
    "    source_folder='/Users/bineshkumar/Documents/mimic-cxr-jpg/2.1.0/files/'\n",
    "elif os_name == \"Linux\":\n",
    "    DB_URL = get_from_cnfg(\"cd_url\",cnfig_file)\n",
    "    gem_key=get_from_cnfg(\"gem_token\",cnfig_file)\n",
    "    oai_key=get_from_cnfg(\"oai_token\",cnfig_file)\n",
    "    source_folder=\"\"\n",
    "engine = create_engine(DB_URL)"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "zftRNEw1stLO",
    "ExecuteTime": {
     "end_time": "2025-03-03T04:59:56.607255Z",
     "start_time": "2025-03-03T04:59:56.604737Z"
    }
   },
   "source": [
    "def insert_model_response(engine, uid,question_id,question, question_category, actual_answer, model_name, model_answer, image_link):\n",
    "    from sqlalchemy import text\n",
    "    with engine.connect() as conn:\n",
    "        trans = conn.begin()\n",
    "        try:\n",
    "            conn.execute(text(\"\"\"\n",
    "                INSERT INTO model_responses_r2\n",
    "                (uid,question_id,question, question_category, actual_answer, model_name, model_answer, image_link)\n",
    "                VALUES (:uid,:question_id,:question, :question_category, :actual_answer, :model_name, :model_answer, :image_link)\n",
    "            \"\"\"), {\n",
    "                \"uid\": uid,\n",
    "                \"question_id\": question_id,\n",
    "                \"question\": question,\n",
    "                \"question_category\": question_category,\n",
    "                \"actual_answer\": actual_answer,\n",
    "                \"model_name\": model_name,\n",
    "                \"model_answer\": model_answer,\n",
    "                \"image_link\": image_link\n",
    "            })\n",
    "            trans.commit()  # Commit the transaction\n",
    "        except Exception as e:\n",
    "            trans.rollback()\n",
    "            raise e"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "I4-EulRd2Mo1",
    "ExecuteTime": {
     "end_time": "2025-03-03T04:59:56.613239Z",
     "start_time": "2025-03-03T04:59:56.611227Z"
    }
   },
   "source": [
    "def check_duplicate(engine,uid,question_id,question, question_category, model_name,image_link):\n",
    "    query = text(\"\"\"\n",
    "        SELECT 1 FROM model_responses_r2\n",
    "        WHERE\n",
    "        uid = :uid\n",
    "        AND question_id = :question_id and\n",
    "        question = :question\n",
    "          AND question_category = :question_category\n",
    "          AND model_name = :model_name\n",
    "          AND image_link = :image_link\n",
    "        LIMIT 1\n",
    "    \"\"\")\n",
    "    with engine.connect() as conn:\n",
    "        result = conn.execute(query, {\n",
    "            \"uid\": uid,\n",
    "            \"question_id\": question_id,\n",
    "            \"question\": question,\n",
    "            \"question_category\": question_category,\n",
    "            \"model_name\": model_name,\n",
    "            \"image_link\": image_link\n",
    "        }).fetchone()\n",
    "    return result is not None"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "0FIav8OWs_6I",
    "ExecuteTime": {
     "end_time": "2025-03-03T04:59:56.619724Z",
     "start_time": "2025-03-03T04:59:56.617345Z"
    }
   },
   "source": [
    "def fetch_generation_data(engine):\n",
    "    import pandas as pd\n",
    "    import re\n",
    "    from sqlalchemy import text\n",
    "    from sqlalchemy.dialects.postgresql.base import PGDialect\n",
    "    def fake_get_server_version_info(self, connection):\n",
    "        version_str = connection.execute(text(\"SELECT version()\")).scalar()\n",
    "        match = re.search(r'v(\\d+)\\.(\\d+)\\.(\\d+)', version_str)\n",
    "        if match:\n",
    "            return tuple(map(int, match.groups()))\n",
    "        return (13, 0, 0)\n",
    "    PGDialect._get_server_version_info = fake_get_server_version_info\n",
    "    query = f\"SELECT id,question_id,condition as question_type, text as question,answer as ground_truth,image from mimic_all_qns; \"\n",
    "    return pd.read_sql(query, con=engine)"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "3h7GpPmrwUKT",
    "ExecuteTime": {
     "end_time": "2025-03-03T04:59:56.626719Z",
     "start_time": "2025-03-03T04:59:56.623670Z"
    }
   },
   "source": [
    "def encode_image_stream(image_path):\n",
    "    if os.path.exists(image_path):\n",
    "        with open(image_path, \"rb\") as img_file:\n",
    "            return base64.b64encode(img_file.read()).decode(\"utf-8\")\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def generate_gpt_response(prompt_text, image_link):\n",
    "    base64_image = encode_image_stream(image_link)\n",
    "    \n",
    "    if base64_image is None:\n",
    "        return None\n",
    "        \n",
    "    client = OpenAI(api_key=oai_key)\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": (\n",
    "                    \"You are an expert medical professional. \"\n",
    "                    \"When responding, provide a concise explanation of the image findings. \"\n",
    "                    \"For example, if asked about abnormalities, answer briefly with terms like 'atelectasis, lung opacity'.\"\n",
    "                )\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"text\",\n",
    "                        \"text\": prompt_text,\n",
    "                    },\n",
    "                    {\n",
    "                        \"type\": \"image_url\",\n",
    "                        \"image_url\": {\"url\": f\"data:image/jpeg;base64,{base64_image}\"}\n",
    "                    },\n",
    "                ],\n",
    "            },\n",
    "        ],\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "def save_failed_images(failed_list, filename=\"failed_images_gpt4o.txt\"):\n",
    "    with open(filename, \"w\") as f:\n",
    "        for img in failed_list:\n",
    "            f.write(f\"{img}\\n\")"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "QonkhLqzV3Gu",
    "ExecuteTime": {
     "end_time": "2025-03-03T04:59:56.632873Z",
     "start_time": "2025-03-03T04:59:56.630572Z"
    }
   },
   "source": [
    "import random\n",
    "from IPython.display import Image, display\n",
    "\n",
    "def print_a_sample(df,prompt_prefix,source_folder=source_folder,width=250):\n",
    "    # Get a random row as a Series\n",
    "    row = df.sample(n=1).iloc[0]  # Add .iloc[0] to get the row as a Series\n",
    "\n",
    "    # Now these will return scalar values\n",
    "    question = row[\"question\"]\n",
    "    actual_answer = row[\"ground_truth\"]\n",
    "    image_link = source_folder + row[\"image\"]\n",
    "\n",
    "    print(f\"{question}\")\n",
    "    print(f\"GT: {actual_answer}\")\n",
    "    print(f\"Image: {image_link}\")\n",
    "\n",
    "\n",
    "    # Uncommented to display the image\n",
    "    display(Image(filename=image_link, width=width))\n",
    "    generated_answer = generate_gpt_response(prompt_prefix + \" \" + row[\"question_type\"] + \":\" + row[\"question\"] + prompt_prefix, image_link)\n",
    "    print(f\"gpt-4o : {generated_answer}\")\n",
    "    print('--------------------------------')\n"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LY98s-3su7dL",
    "jupyter": {
     "is_executing": true
    },
    "outputId": "86871245-9dc2-4e3b-94a9-c412455c9abd"
   },
   "source": [
    "from IPython.display import clear_output\n",
    "model_id = \"gpt-4o\"\n",
    "failed_images = []\n",
    "\n",
    "for index, row in fetch_generation_data(engine).iterrows():\n",
    "    uid = row[\"id\"]\n",
    "    question_id = row[\"question_id\"]\n",
    "    question_category = row[\"question_type\"]\n",
    "    question = row[\"question\"]\n",
    "    actual_answer = row[\"ground_truth\"]\n",
    "    image_link = source_folder + row[\"image\"]\n",
    "    \n",
    "    if check_duplicate(engine, uid, str(question_id), question, question_category, model_id, image_link):\n",
    "        print(f\"Duplicate record found for question: {question}. Skipping generation.\")\n",
    "        clear_output(wait=True)\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        generated_answer = generate_gpt_response(question, image_link)\n",
    "        \n",
    "        if generated_answer is None:\n",
    "            print(f\"Image not found: {image_link}\")\n",
    "            failed_images.append(image_link)\n",
    "            save_failed_images(failed_images)\n",
    "            continue\n",
    "            \n",
    "        print(f\"{model_id} : {generated_answer}\")\n",
    "        print(f\"GT: {actual_answer}\")\n",
    "        insert_model_response(engine, uid, question_id, question, question_category, actual_answer, model_id, generated_answer, image_link)\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating response for question: {question}. Error: {e}\")\n",
    "        continue\n",
    "    \n",
    "    time.sleep(5)\n",
    "    print('--------------------------------')\n",
    "    clear_output(wait=True)\n",
    "\n",
    "save_failed_images(failed_images)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
